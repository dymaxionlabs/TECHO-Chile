{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e08096",
   "metadata": {},
   "source": [
    "## 1) Creaci칩n de dataset entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4193e4",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607185fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo librerias\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98cb04",
   "metadata": {},
   "source": [
    "### Instalacion de pysatproc (correr solo una vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e29c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip instal pysatproc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289834e",
   "metadata": {},
   "source": [
    "### Variables para configuracion de satproc_extract_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60695bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates=\"2021-01-01_2021-03-01\"                                      # nombre de la carpeta con las imagenes\n",
    "zona = \"zona_3\"                                                    # zona con la que vamos a trabajar\n",
    "version =  2                                                       # version de la corrida actual \n",
    "size = 100                                                         # tama침o (pixeles) de las imagenes que se van a generar\n",
    "step_size = 50                                                     # tama침o de la ventana\n",
    "vector_file_path = \"../data/shp/gt/R3/Asentamiento_R3_v2.geojson\"  # ruta y archivo con la verdad de campo\n",
    "\n",
    "###### estas variables no modifican #####\n",
    "path_to_files = os.path.join(\"../images-S2\",zona,dates,\"*.tif\")    # ruta a la carpeta con las imagenes satelitales\n",
    "vector_aoi_file_path = vector_file_path\n",
    "output_folder = os.path.join(\"../dataset/data_train\",zona,\"v\"+str(version),str(size)+\"_\"+str(step_size))         # Destination path <ndim>/<size>_<step-size>/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a858f8c",
   "metadata": {},
   "source": [
    "### Lista de imagenes que van a ser procesadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc991d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $path_to_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd344ec9",
   "metadata": {},
   "source": [
    "### Ayuda de satproc_extract_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#satproc_extract_chips --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a5258",
   "metadata": {},
   "source": [
    "### Generacion del dataset para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo el dataset para entrenamiento (imag + anotaciones)\n",
    "!satproc_extract_chips \\\n",
    "    $path_to_files \\\n",
    "    -o  $output_folder \\\n",
    "    --size $size \\\n",
    "    --step-size $step_size \\\n",
    "    --aoi $vector_file_path \\\n",
    "    --labels $vector_file_path \\\n",
    "    --label-property 'class' \\ # nombre del campo que tiene la clase a predecir\n",
    "    --classes 'A' \\            # valor que toma la clase a predecir\n",
    "    --rescale \\\n",
    "    --rescale-mode s2_rgb_extra --lower-cut 1 --upper-cut 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb62739",
   "metadata": {},
   "source": [
    "# 2) Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e757608",
   "metadata": {},
   "source": [
    "### Instalacion de unet (correr solo una vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install unetseg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5d2d8",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo la red neuronal\n",
    "from unetseg.train import TrainConfig, train\n",
    "from unetseg.evaluate import plot_data_generator\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2a820",
   "metadata": {},
   "source": [
    "### Variables para configuracion de unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "spe=100          # step per epoch (debe ser multipo de 16 y estar entre 80 y 320)\n",
    "size_unet=160    # tama침o en la red (img/batch_size 10%)\n",
    "\n",
    "config = TrainConfig(width=size_unet,  \n",
    "                     height=size_unet, \n",
    "                     n_channels=4, \n",
    "                     n_classes=1,\n",
    "                     apply_image_augmentation=True,\n",
    "                     seed=42,\n",
    "                     epochs=30, \n",
    "                     batch_size=16, \n",
    "                     steps_per_epoch=spe, \n",
    "                     early_stopping_patience=10,\n",
    "                     validation_split=0.1, \n",
    "                     test_split=0.1,  \n",
    "                     model_architecture='unet', #unetplusplus\n",
    "                     images_path=os.path.join(\"../dataset/data_train\",zona,'v'+str(version),str(size)+\"_\"+str(step_size)),                     \n",
    "                     model_path=os.path.join('../data/weights/model',zona+'_UNet_techo_4D_spe'+str(spe)+'_img'+str(size)+'_size'+str(size)+'_sz'+str(step_size)+'.h5'),\n",
    "                     evaluate=True ,\n",
    "                     class_weights = [1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084a190",
   "metadata": {},
   "source": [
    "### Grafico de 3 tiles al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_generator(num_samples=3, fig_size=(10, 10), train_config = config,img_ch = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f75327",
   "metadata": {},
   "source": [
    "### Corro el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398f641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Corro el modelo con los parametros establecidos\n",
    "res_config = train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee38bac",
   "metadata": {},
   "source": [
    "### Graficos Loss y Mean_iou de train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(res_config.history['loss'])\n",
    "plt.plot(res_config.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(res_config.history['mean_io_u'])\n",
    "plt.plot(res_config.history['val_mean_io_u'])\n",
    "plt.title('mean_iou')\n",
    "plt.ylabel('val_mean_iou')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
