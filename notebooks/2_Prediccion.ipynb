{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5716e9b2",
   "metadata": {},
   "source": [
    "## 2)  Creación de dataset prediccion\n",
    "\n",
    "En esta etapa generamos las imágenes que utilizará el modelo para el entrenamiento y la predicción. \n",
    "\n",
    "Utilizando las imágenes generadas en el paso anterior y la información vectorial de la ubicación de los asentamientos, generamos el dataset utilizado luego por el modelo de ML. Este dataset se genera con el formato necesario para el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0949c",
   "metadata": {},
   "source": [
    "### Instalacion de pysatproc (correr solo una vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pysatproc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907234f",
   "metadata": {},
   "source": [
    "### Variables para configuracion de satproc_extract_chips\n",
    "Definimos el la configuracion para la predicción. Debemos pasar la ruta a las imagenes del dataset de prediccion y al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_files = \"../images-S2/zona_4/2021-01-01_2021-03-01/*.tif\"             # ruta a las imagenes satelitales\n",
    "output_folder = \"../dataset/data_predict/zona_4/v2/160_80/\"                   # ruta donde se van a dejar las imagenes porcesadas\n",
    "vector_aoi_file_path = \"../data/shp/predict_aoi_zona4_buff5km_4326.geojson\"   # archivo geojson con el area de interes                       \n",
    "size = 160                                                                    # stamaño (pixeles) de las imagenes que se van a generar\n",
    "step_size = size                                                              # tamaño de la ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec993a8e",
   "metadata": {},
   "source": [
    "### Generación del dataset para predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509cc35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creo dataset para prediccion (solo imagenes)\n",
    "!satproc_extract_chips $path_to_files \\\n",
    "    -o $output_folder \\\n",
    "    --aoi $vector_aoi_file_path \\\n",
    "    --size $size \\\n",
    "    --step-size $step_size \\\n",
    "    --rescale \\\n",
    "    --rescale-mode s2_rgb_extra --lower-cut 1 --upper-cut 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1a62f",
   "metadata": {},
   "source": [
    "# 3) Prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17762eef",
   "metadata": {},
   "source": [
    "### Librerias\n",
    "Descargamos la librería os para la navegación de archivos, y unetseg para la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac060880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo librerias\n",
    "from unetseg.predict import PredictConfig, predict\n",
    "from unetseg.evaluate import plot_data_results\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d14b5d",
   "metadata": {},
   "source": [
    "### Variables para configuracion de la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zona='zona_4'\n",
    "version = 'v2'\n",
    "size_stepsize='160_80'\n",
    "\n",
    "predict_config = PredictConfig(\n",
    "                                    images_path = os.path.join('../dataset/data_predict',zona,version,size_stepsize),\n",
    "                                    results_path = os.path.join('../dataset/data_results',zona,version,size_stepsize),\n",
    "                                    batch_size=16,\n",
    "                                    model_path='../data/weights/model/zona_3UNet_techo_4D_spe100_img160_size160_sz80.h5',  #  ruta al modelo (.h5)\n",
    "                                    height=160,\n",
    "                                    width=160,\n",
    "                                    n_channels=4,\n",
    "                                    n_classes=1,\n",
    "                                    class_weights=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962be2e5",
   "metadata": {},
   "source": [
    "### Corro la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(predict_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e9542-da1d-418c-9c88-33bf2fc3d19b",
   "metadata": {},
   "source": [
    "## Funcion para ver algunos resultados preliminales de la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986de3fc-ed29-4bfd-a0bd-741ede70a84b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def plot_data_results_(\n",
    "    num_samples: int = 3,\n",
    "    fig_size=(20, 10),\n",
    "    *,\n",
    "    predict_config: PredictConfig,\n",
    "    img_ch: int = 3,\n",
    "    n_bands: int = 3\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots some samples from the results directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_samples : int\n",
    "        Number of samples to plot.\n",
    "    fig_size : tuple\n",
    "        Figure size.\n",
    "    img_ch : int\n",
    "        Number of channels.\n",
    "    predict_config : PredictConfig\n",
    "        Prediction onfiguration object.\n",
    "    \"\"\"\n",
    "\n",
    "    images = [\n",
    "        os.path.basename(f)\n",
    "        for f in sorted(glob(os.path.join(predict_config.results_path, \"*.tif\")))\n",
    "    ]\n",
    "\n",
    "    images = random.sample(images, num_samples)\n",
    "    for img_file in images:\n",
    "        try:\n",
    "            if n_bands not in (1, 3):\n",
    "                raise RuntimeError(\"n_bands option must be 1 or 3\")\n",
    "            \n",
    "            fig, axes = plt.subplots(\n",
    "                nrows=1, ncols=predict_config.n_classes + 1, figsize=(20, 40)\n",
    "            )\n",
    "                 \n",
    "            if n_bands == 1:\n",
    "          \n",
    "                img_s2 = tiff.imread(\n",
    "                    os.path.join(predict_config.images_path, \"images\", img_file)\n",
    "                )[:, :, img_ch]\n",
    "                axes[0].imshow(img_s2)\n",
    "               \n",
    "            if n_bands == 3:\n",
    "             \n",
    "                img_s2 = tiff.imread(\n",
    "                    os.path.join(predict_config.images_path, \"images\", img_file)\n",
    "                )[:, :, :3]\n",
    "                axes[0].imshow(img_s2)\n",
    "            \n",
    "            # Prediccion\n",
    "            mask_ = (\n",
    "                tiff.imread(os.path.join(predict_config.results_path, img_file)) / 255\n",
    "            )\n",
    "   \n",
    "            mask_ = resize(\n",
    "                mask_,\n",
    "                (predict_config.height, predict_config.width, predict_config.n_classes),\n",
    "                mode=\"constant\",\n",
    "                preserve_range=True,\n",
    "            )\n",
    "\n",
    "          \n",
    "           \n",
    "            \n",
    "\n",
    "            for c in range(predict_config.n_classes):\n",
    "                axes[1 + c].imshow(np.squeeze(mask_[:, :, c]))\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13bc43a-e696-49c8-b01a-92976c02543a",
   "metadata": {},
   "source": [
    "### Vemos algunos resultados preliminares de la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee609a7-75ae-4ea1-ab39-4e5465d74fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_results_(num_samples=5, fig_size=(5, 5), predict_config=predict_config, img_ch =3,n_bands =3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b949ee",
   "metadata": {},
   "source": [
    "## 4) Post-procesamiento\n",
    "Post-procesamiento que fueron aplicados sobre los resultados de las predicciones del modelo de U-Net."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddcea7f",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from satproc.postprocess.polygonize import polygonize \n",
    "from satproc.filter import filter_by_max_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ff302",
   "metadata": {},
   "source": [
    "### Filtramos las predicciones con probabilidad mayor al parametro y poligonos mayor a una superficie determinada\n",
    "\n",
    "Aplica una rutina de poligonización sobre los resultados de la predicción del modelo y genera un archivo vectorial en formato GeoPackage (GPKG). La rutina aplica `gdal_polygonize.py` a cada chip resultado generando un GPKG para cada chip, y luego une todos estos archivos en uno solo, de manera eficiente.\n",
    "\n",
    "Antes de unirlos también aplica un umbral sobre los valores de los rásteres, que en este caso representan la probabilidad (valores entre 0 y 1).\n",
    "\n",
    "Como último paso, filtramos aquellos polígonos de area inferior a 500 m², dado que consideramos que son falsos positivos. Para esto utilizamos `ogr2ogr` y una consulta SQL. El resultado se guarda en `dataset/data_results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametro_prob=0.3 # parametro a filtrar\n",
    "min_area = 500     # superficie minima a fitrar\n",
    "\n",
    "# creamos una carpeta\n",
    "carpeta = os.path.join('../dataset/data_results',zona,version,size_stepsize)+'_filtered_up'+str(parametro_prob).split('.')[0]+str(parametro_prob).split('.')[1]+'/'\n",
    "!mkdir -p $carpeta\n",
    "\n",
    "# filtramos por la probabilidad \"parametro_prob\"\n",
    "filter_by_max_prob(input_dir = os.path.join('../dataset/data_results',zona,version,size_stepsize),\n",
    "                   output_dir = os.path.join('../dataset/data_results',zona,version,size_stepsize)+'_filtered_up'+str(parametro_prob).split('.')[0]+str(parametro_prob).split('.')[1]+'/',\n",
    "                   threshold = parametro_prob) #Probar ≠ prob umbrales, por ahi, empezar con 0.1\n",
    "\n",
    "\n",
    "# generamos los poligonos\n",
    "input_path =  os.path.join('../dataset/data_results',zona,version,size_stepsize)+'_filtered_up'+str(parametro_prob).split('.')[0]+str(parametro_prob).split('.')[1]+'/'\n",
    "output_path = os.path.join('../dataset/data_results',zona,version+'_'+size_stepsize+'_'+zona+'_thr_'+str(parametro_prob).split('.')[0]+str(parametro_prob).split('.')[1]+'.gpkg')\n",
    "polygonize(threshold=parametro_prob,\n",
    "          # value=100,\n",
    "           input_dir=input_path,\n",
    "           output=output_path)\n",
    "\n",
    "# pasamos a proyeccion utm para poder usar metros cuadrados como medida de superficie\n",
    "src_file = os.path.join('../dataset/data_results',zona,version+'_'+size_stepsize+'_'+zona+'_thr_'+str(parametro_prob).split('.')[0]+str(parametro_prob).split('.')[1]+'.gpkg')\n",
    "dst_file = os.path.join('../dataset/data_results',zona,version+'_'+size_stepsize+'_'+zona+'_thr_'+str(parametro_prob).split('.')[0]+str(parametro_prob).split('.')[1]+'_utm.gpkg')\n",
    "!ogr2ogr -s_srs EPSG:4326 -t_srs EPSG:32720 -f 'ESRI Shapefile' $dst_file $src_file #lo puedo abrir en QGIS como archivo vectorial\n",
    "        \n",
    "        \n",
    "# filtramos los que sean mas chico que el parametro \"min_area\"\n",
    "input_path = os.path.join('../dataset/data_results',zona,version+'_'+size_stepsize+'_'+zona+'_thr_'+str(parametro_prob).split('.')[0]+str(parametro_prob).split('.')[1]+'_utm.gpkg')\n",
    "output_path = input_path.replace(\".gpkg\", \"_up\"+str(min_area)+\".gpkg\")    \n",
    "tabla = input_path.split(\"/\",-1)[-1].strip('.gpkg').strip('_utm')\n",
    "sql = \"SELECT * FROM \"+tabla+\" m WHERE ST_Area(geometry) > \"+str(min_area)        \n",
    "\n",
    "!ogr2ogr -t_srs EPSG:32720 -f \"GPKG\" -sql \"$sql\" -dialect SQLITE -nln results $output_path $input_path\n",
    "\n",
    "print('Archivo generado correctamente',output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
